# FrugalClassifier
One major hurdle faced while Machine Learning is the accumulation and efficient utilization of test and training data .
It is often, a very expensive, time consuming and combursome process to collect the training observations.
And even after a great deal of effort has been put into collecting this data, a uniformaly accurate classifier can not be guaranteed. The Classifier implemented here, severely reduces the above mentioned burden by performing classification "on the fly" and using a feedback system, to checks the nature of training data, it requires to improve it's own accuracy ! The classifer works on the principle of multi-level classification and "best of three" principle , to sort observations into one or more classes. It simultaneously recognizes those classes , for which the accuracy of classification is below a pre-defined threshold. Given a class "c", As long as the accuracy of class 'c' is below the threshold "T", the class is in the "unstable bag" and the classifer keeps demanding regular training data and test data to improve its accuracy for that perticular class. However, as soon as the accuracy( which is the reciprocal of the error component) for "c" reaches above the threshold, it is dumped into a separate bag called the "stable bag".
The classes in the safe/stable bag are given less emphasis compared to the "un-safe" classes. test and training data for safe classes are only occasionally and randomly demanded. Un-safe classes are regularly scrutinized and given much more "training and test data" to improve their accuracy. We continue to perform these steps until all the classes have reached an accuracy > T.
The classifer can also be set of change the Threshold value "T" for each class.

